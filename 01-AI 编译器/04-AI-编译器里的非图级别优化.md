# AI 编译器里的非图级别优化

## 内存管理优化

优化思路：

1. 调整分配/释放的时间点和次数，尽可能减少运行时的分配/释放内存带来的时间开销；
2. 优化分配过程，尽可能减少总的内存占用。

惰性内存分配器（LazyAllocator）：在推理开始之前分析整个计算图中 tensor 占用内存的可复用情况，并预分配每个 tensor 的偏移地址，总的内存占用为推理过程的内存峰值。

## 与硬件无关的算子优化

以 transpose 算子为例，可进行的与硬件无关的优化有：

1. 去除形状里大小为 1 的维度；
2. 合并连续的维度；
3. 合并末尾连续访存。

结论：即使不操作图也不修改 kernel 也能优化性能。

## tuning 技术

推理框架后端可能会有多种 kernel 实现，例如调用算子库的 kernel、手写的 kernel 和代码生成的 kernel 等。在调用算子进行推理计算时，我们需要选择一个性能最好的 kernel 作为我们实际调用的 kernel，由于每个 kernel 自己可能也有多种实现，所以对于每个 kernel 来说，也需要选择自己最优的算法配置。

## 生成和执行任务图

使用该技术分为三个不同的阶段：定义（definition），实例化（instantiation）和执行（execution）。

- 在定义阶段，程序在图中创建各个操作描述以及它们之间的依赖关系。
- 在实例化阶段会记录 graph 中各操作执行的快照，对其进行验证，并执行大部分设置和初始化工作，目的是最大限度地减少启动时需要完成地工作。在这一步生成的实例称为可执行图。
- 可执行图可以在流中被启动，类似于任何其他的 device 侧任务。它可以被启动任意多次，而无需重复实例化。  
